{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "80ed7627-23bf-437e-9727-f46a190336a5",
      "cell_type": "raw",
      "source": "lotlib inlinelotlib inline",
      "metadata": {}
    },
    {
      "id": "f21f61f9-58ca-40e1-b9f1-277dfac68e0f",
      "cell_type": "code",
      "source": "import io\nimport os\nimport matplotlib.pyplot as plt\nimport numpy as np \nimport pandas as pd \n\nimport json #converting JSON to lists for dataframe\nimport warnings\nwarnings.filterwarnings('ignore')\nimport base64\nimport codecs\nfrom IPython.display import HTML\n\n%matplotlib inline",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0de117a7-12f8-47ef-9e2f-c346fb27e0f0",
      "cell_type": "code",
      "source": "movie1 = pd.read_csv(\"../input/tmdb-movie-metadata/tmdb_5000_movies.csv\")\nmovie2 = pd.read_csv(\"../input/tmdb-movie-metadata/tmdb_5000_credits.csv\")\n\nmovies = movie1.merge(movie2,left_on='id',right_on='movie_id',how='left')# merging the two csv files",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8aa62c39-7cf3-4d39-ac86-5530e596f248",
      "cell_type": "code",
      "source": "movies = movies[(movies['vote_average']!=0)]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "1cb9b582-52a7-43e2-b3dd-94c09fe57214",
      "cell_type": "code",
      "source": "movies.sample(5)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "aff7a050-828c-4461-83e3-b86001481e06",
      "cell_type": "code",
      "source": "def to_list(df, feature_names_list): #df: dataframe, feature_names: list of all features to convert from JSON to list\n    for feature_name in feature_names_list:\n        print(\"Current:\", feature_name)\n        #STEP 1: convert JSON format to a list\n        df[feature_name]=df[feature_name].apply(json.loads)\n        #Two cases here: Feature is crew, or feature is not crew\n        if feature_name == 'crew': #if crew, due to large size, want to limit to most influential members: director, editor, cinematographer, screenplay, and composer\n            for index,i in zip(df.index,df[feature_name]):\n                feature_list_1=[]\n                limit = 10\n                if len(i) < 10:\n                    limit = len(i)\n                for j in range(limit): #top 10 crew members\n                    feature_list_1.append((i[j]['name'])) # the key 'name' contains the name of the a sub-feature (ex: sci-fi in genres)\n                df.loc[index,feature_name]= str(feature_list_1)\n        \n        elif feature_name == 'cast': #Another special case. Only want top 5 cast members (most infulential)\n            for index,i in zip(df.index,df[feature_name]):\n                feature_list_1=[]\n                if len(i) > 5:\n                    limit = 5\n                else:\n                    limit = len(i)\n                for j in range(limit): #top 5 (JSON format already has this sorted)\n                    feature_list_1.append((i[j]['name']))\n                df.loc[index,feature_name]= str(feature_list_1)\n        else:    \n            for index,i in zip(df.index,df[feature_name]):\n                feature_list_1=[]\n                for j in range(len(i)):\n                    feature_list_1.append((i[j]['name']))\n                df.loc[index,feature_name]= str(feature_list_1)\n    \n        #STEP 2: clean up and transform into unsorted list\n        df[feature_name] = df[feature_name].str.strip('[]').str.replace(' ','').str.replace(\"'\",'')\n        df[feature_name] = df[feature_name].str.split(',')\n        \n        #STEP 3: Sort list elements\n        for i,j in zip(df[feature_name],df.index):\n            features_list_2=i\n            features_list_2.sort()\n            df.loc[j,feature_name]=str(features_list_2)\n        df[feature_name]=df[feature_name].str.strip('[]').str.replace(' ','').str.replace(\"'\",'')\n        lst = df[feature_name].str.split(',')\n        if len(lst) == 0:\n            df[feature_name] = None\n        else:\n            df[feature_name]= df[feature_name].str.split(',')\n    return df",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6e1c27b6-2019-411f-9749-86cab5a5edf0",
      "cell_type": "code",
      "source": "movies = to_list(movies, ['genres', 'keywords', 'production_companies', 'cast', 'crew']) #function call",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "eb220459-049a-44b3-a877-f708df0e6d77",
      "cell_type": "code",
      "source": "to_drop = []\nfor i in movies.index:\n    if (movies['production_companies'][i] == [''] and movies['cast'][i] == [''] and \n        movies['crew'][i] == ['']):\n        to_drop.append(i)\nprint('Dropping', str(len(to_drop)), 'movies.')\nmovies = movies.drop(to_drop, axis = 0)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3c787e3d-2452-49ba-8437-8b7fde98de10",
      "cell_type": "code",
      "source": "movies.shape[0]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a6975a82-4cf2-47a8-a8f8-a2697494d790",
      "cell_type": "code",
      "source": "movies_shortened = movies[['id','original_title','genres','cast', 'crew', 'production_companies', 'keywords', 'vote_average']]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c318f6da-ff75-4d2b-96fa-576b1ed364a4",
      "cell_type": "code",
      "source": "movies_shortened.sample(10)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3b51bff0-4a24-47c0-9136-1e69114314de",
      "cell_type": "code",
      "source": "plt.subplots(figsize=(12,10))\nn, bins, patches = plt.hist(movies_shortened['vote_average'], 30, density=1, facecolor='g', alpha=0.75)\n\nplt.xlabel('Vote_average')\nplt.ylabel('Occurence')\nplt.title('Distribution of voter average')\nplt.grid(True)\nplt.show()\nprint(\"Minimum of Ratings:\", round(min(movies_shortened['vote_average']),2))\nprint(\"Maximum of Ratings:\", round(max(movies_shortened['vote_average']),2))\nprint(\"Average of Ratings:\", round(np.mean(movies_shortened['vote_average']),2))\nprint(\"Variance of Ratings:\",round(np.var(movies_shortened['vote_average']),2))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4369845e-66f2-444b-8ce1-ae315f172b39",
      "cell_type": "code",
      "source": "def generate_list(df, feature_name): #create a list of all unique feature values\n    #Step 1: track all ratings associated with each feature in a dictionary\n    feature_dict = {}\n    for index, row in df.iterrows():\n        feat = row[feature_name]\n        for sub_feat in feat:\n            if sub_feat not in feature_dict:\n                feature_dict[sub_feat] = (df['vote_average'][index], 1) #\n            else:\n                feature_dict[sub_feat] = (feature_dict[sub_feat][0] + (df['vote_average'][index]), feature_dict[sub_feat][1] + 1)\n    #Step 2: calculate average ratings for each feature\n    for key in feature_dict:\n        feature_dict[key] = feature_dict[key][0]/feature_dict[key][1] #average of all vote_averages\n    #Step 3: create and sort a list of tuples (dictionary value, key)\n    lst = list()\n    for name in feature_dict:\n        lst.append((feature_dict[name],name))\n    lst = sorted(lst)\n    #step 4: create a list of only the feature names, from lowest rating to highest rating\n    feature_list = list()\n    ratings_list = list()\n    for element in lst:\n        feature_list.append(element[1])\n        ratings_list.append(element[0])\n    \n    #get the variance of the ratings. This is helpful for determining the usefulness of the information (to be displayed in below plot)\n    var = round(np.var(ratings_list),3)\n    \n    #before returning the list, do a quick visualization to show that generate_list works\n    fig, ax = plt.subplots(figsize=(6,5))\n    if feature_name != 'genres':\n        n = 50 # sample at intervals of n\n    else:\n        n = 1\n     X = [] #sample for associated movie(s) rating average\n    Y = [] #sample for feature names\n    for i in range(0, len(feature_list) - 1, n):\n        X.append(ratings_list[i])\n        Y.append(feature_list[i])\n    \n    y_pos = np.arange(len(Y))\n    ax.barh(y_pos, X, align='center')\n    #ax.set_yticklabels(Y)\n    ax.invert_yaxis()  # labels read top-to-bottom\n    \n    ax.set_xlabel('Overall average movie ratings')\n    ax.set_ylabel(feature_name + ' sample list index')\n    ax.set_title(feature_name + ' to associated movie(s) performance (' + str(int(len(feature_list)/n)) + ' samples), variance: ' + str(var))\n    \n    plt.show()\n    \n    return feature_list    ",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "cefe24b8-425f-4264-847d-819f7149fd14",
      "cell_type": "code",
      "source": "genres_list = generate_list(movies_shortened, 'genres')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "57ca43f4-19f6-4b22-9827-3ec167569719",
      "cell_type": "code",
      "source": "cast_list = generate_list(movies_shortened, 'cast')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2455ef48-cb72-4e69-a832-cf1cf8ad3979",
      "cell_type": "code",
      "source": "crew_list = generate_list(movies_shortened, 'crew')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "55bdda20-2330-4a9f-8450-6b8df83c203f",
      "cell_type": "code",
      "source": "prod_companies_list = generate_list(movies_shortened, 'production_companies')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4b5f61cd-339a-4ea6-a77d-e580ba699752",
      "cell_type": "code",
      "source": "keywords_list = generate_list(movies_shortened, 'keywords')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "9cb64267-8d80-4bc4-96a5-830fc396bc78",
      "cell_type": "code",
      "source": "movies_shortened = movies_shortened[['id', 'original_title', 'cast', 'crew', 'production_companies', 'keywords','vote_average']]\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c716ddac-931b-4979-a46f-c41ab7fb13fd",
      "cell_type": "code",
      "source": "def calculate_bin_array(this_list, all_features):\n    bin_list = []\n    for element in all_features:\n        if element in this_list:\n            bin_list.append(1)\n        else:\n            bin_list.append(0)\n    return bin_list",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "400bd832-b058-4bd3-a8df-16949c4f8f83",
      "cell_type": "code",
      "source": "movies_shortened['cast'] = movies_shortened['cast'].apply(lambda x: calculate_bin_array(x, cast_list))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "244c8cbf-42a6-4fd9-9c9b-926404e977a4",
      "cell_type": "code",
      "source": "movies_shortened['crew'] = movies_shortened['crew'].apply(lambda x: calculate_bin_array(x, crew_list))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5bdfa7e1-a6c3-4890-ace1-11830d332a60",
      "cell_type": "code",
      "source": "movies_shortened['production_companies'] = movies_shortened['production_companies'].apply(lambda x: calculate_bin_array(x, prod_companies_list))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "29b3ea7f-dac3-40a4-a8ad-53453b7d0dd8",
      "cell_type": "code",
      "source": "movies_shortened['keywords'] = movies_shortened['keywords'].apply(lambda x: calculate_bin_array(x, keywords_list))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "02141da4-34c9-46fa-a6ab-ff1096b91a05",
      "cell_type": "code",
      "source": "movies_shortened.sample(10)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6c71a090-2737-4a45-976f-97a4a777be24",
      "cell_type": "code",
      "source": "def plot_bin(mov):\n    cast_bin = mov[2]\n    cast_index = []\n    # create arrays of indeces where bin number is one\n    for i in range(len(cast_bin)):\n        if cast_bin[i] == 1:\n            cast_index.append(i)\n    \n    crew_bin = mov[3]\n    crew_index = []\n    for i in range(len(crew_bin)):\n        if crew_bin[i] == 1:\n            crew_index.append(i)\n    \n    prod_bin = mov[4]\n    prod_index = []\n    for i in range(len(prod_bin)):\n        if prod_bin[i] == 1:\n            prod_index.append(i)\n    keywords_bin = mov[5]\n    keywords_index = []\n    for i in range(len(keywords_bin)):\n        if keywords_bin[i] == 1:\n            keywords_index.append(i)\n    \n    font = {'family': 'serif',\n        'color':  'red',\n        'weight': 'normal',\n        'size': 10,\n        }\n    \n    fig, ax = plt.subplots(4,1,figsize=(5,1))\n    plt.subplots_adjust(hspace = 5)\n    ax[0].scatter(cast_index, np.zeros_like(cast_index), vmin=-2)\n    ax[0].set_title('Cast', loc = 'left', fontdict=font)\n    ax[0].set_xlim(0,len(cast_bin))\n    ax[0].set_yticks([])\n    ax[0].set_xticks([])\n    \n    ax[1].scatter(crew_index, np.zeros_likke(crew_index), vmin=-2)\n    ax[1].set_title('Crew', loc = 'left', fontdict=font)\n    ax[1].set_xlim(0,len(crew_bin))\n    ax[1].set_yticks([])\n    ax[1].set_xticks([])\n    \n    ax[2].scatter(prod_index, np.zeros_like(prod_index), vmin=-2)\n    ax[2].set_title('Production companies', loc = 'left', fontdict=font)\n    ax[2].set_xlim(0,len(prod_bin))\n    ax[2].set_yticks([])\n    ax[2].set_xticks([])\n    \n    ax[3].scatter(keywords_index, np.zeros_like(keywords_index), vmin=-2)\n    ax[3].set_title('Keywords', loc = 'left', fontdict=font)\n    ax[3].set_xlim(0,len(keywords_bin))\n    ax[3].set_yticks([])\n    ax[3].set_xticks([])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "31d9cd98-9847-43c0-8b33-3271255dee55",
      "cell_type": "code",
      "source": "movies_sample = movies_shortened.sample(5)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3c856c4f-c329-4a26-a761-48f725eb5562",
      "cell_type": "code",
      "source": "print('Movie: ' + movies_sample.iloc[0][1] + '\\nRating: ' + str(movies_sample.iloc[0][-1]) + '\\n')\nplot_bin(movies_sample.iloc[0])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "82277977-ace3-4fb9-93cd-3c415a90b7a3",
      "cell_type": "code",
      "source": "print('Movie:' + movies_sample.iloc[1][1] + '\\nRating: ' + str(movies_sample.iloc[1][-1]) + '\\n')\nplot_bin(movies_sample.iloc[1])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d0d2337d-12db-4590-bb7c-abddd70102f2",
      "cell_type": "code",
      "source": "print('Movie:' + movies_sample.iloc[2][1] + '\\nRating: ' + str(movies_sample.iloc[2][-1]) + '\\n')\nplot_bin(movies_sample.iloc[2])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2534bf5c-c4eb-4eb4-83b9-ff1e2d6be07b",
      "cell_type": "code",
      "source": "print('Movie:' + movies_sample.iloc[3][1] + '\\nRating: ' + str(movies_sample.iloc[3][-1]) + '\\n')\nplot_bin(movies_sample.iloc[3])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "96606484-1ecc-40dd-aab2-7620a9e25164",
      "cell_type": "code",
      "source": "print('Movie:' + movies_sample.iloc[4][1] + '\\nRating: ' + str(movies_sample.iloc[4][-1]) + '\\n')\nplot_bin(movies_sample.iloc[4])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "962e60c6-3161-4541-92d5-8191efc28d22",
      "cell_type": "code",
      "source": "def split_arr(arr, n_splits): \n      \n    # looping till length l \n    for i in range(0, len(arr), n_splits):  \n        yield arr[i:i + n_splits] \n\ndef find_concentration(arr, n = 100): # n is the number of concentration points to find\n    #seperate array into batches\n    batches = list(split_arr(arr,int(len(arr)/n)))\n    concentrations = []\n    for i in range(len(batches)):\n        point = 0\n        num_ones = 0\n        for j in range(len(batches[i])):\n            if batches[i][j] == 1:\n                point += j + (i * int(len(arr)/n)) # adding correction for batches\n                num_ones += 1\n        if num_ones > 0:\n            point = point/num_ones\n            concentrations.append((point,num_ones))\n    return concentrations        ",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e97abf89-3f6b-44cc-aa4c-7d403f15b5c6",
      "cell_type": "code",
      "source": "def to_concentrations(df, feature_names):\n    for feature_name in feature_names:\n        print('feature: ', feature_name)\n        df[feature_name] = df[feature_name].apply(lambda x: find_concentration(x))\n    return df",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "aee46cf1-6a05-4587-9c1b-21aa6c9cd4b5",
      "cell_type": "code",
      "source": "movies_shortened = to_concentrations(movies_shortened, ['cast', 'crew', 'production_companies', 'keywords'])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "268f2ca9-20b4-49e3-99cf-14a74d62a1a2",
      "cell_type": "code",
      "source": "movies_shortened.sample(10)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "33562cf9-f2f5-428c-a52c-4dceafcb9de5",
      "cell_type": "code",
      "source": "def w_avg(arr):\n    weight = 0 #weight\n    s = 0 # position*weight\n    for element in arr:\n        s += (element[0] * element[1])\n        weight += element[1]\n    return s/weight #weighted average",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "bd32b88d-0909-406d-9687-af3a623cb63b",
      "cell_type": "code",
      "source": "def to_weighted_avg(df, feature_names):\n    for feature_name in feature_names:\n        print('Current: ', feature_name)\n        df[feature_name] = df[feature_name].apply(lambda x: w_avg(x))\n    return df",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "7ef9e42b-e127-4109-841e-05542d0c700f",
      "cell_type": "code",
      "source": "movies_shortened = to_weighted_avg(movies_shortened, ['cast', 'crew', 'production_companies', 'keywords'])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "505feb4a-9621-408f-bc24-743f74fd0880",
      "cell_type": "code",
      "source": "movies_shortened['vote_average'] = movies['vote_average']",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "133cbe15-fa4d-46a2-85b6-c655708e762e",
      "cell_type": "code",
      "source": "movies_shortened.sample(10)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3fb09bc0-235c-4fd6-aa54-d69714427061",
      "cell_type": "code",
      "source": "feat_df = movies_shortened[['cast', 'crew', 'production_companies', 'keywords']] #extract only features from df, and scale",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "bac7c1c6-f8e1-4330-9359-38f0a4f959ec",
      "cell_type": "code",
      "source": "from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nfeat_scaled = pd.DataFrame(scaler.fit_transform(feat_df.astype(float)))\nfeat_scaled.index = feat_df.index\nfeat_scaled.columns = feat_df.columns\n\n#Seperate dataframe for target\ntarget_df = pd.DataFrame()\ntarget_df['ratings'] =  movies_shortened['vote_average']",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "77a79a43-3cb4-408c-9cc8-c959279adbd2",
      "cell_type": "code",
      "source": "feat_scaled.sample(10)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f06fbf4d-0788-49b1-b664-b33a44c9d1f3",
      "cell_type": "code",
      "source": "fig, ax = plt.subplots(2,2, figsize=(24,20))\n\nax[0,0].scatter(target_df['ratings'], feat_scaled['cast'], facecolor='blue')\nax[0,0].set_xlabel('rating')\nax[0,0].set_ylabel('cast normalized')\nax[0,0].set_title('cast')\n\nax[1,0].scatter(target_df['ratings'], feat_scaled['crew'], facecolor='green')\nax[1,0].set_xlabel('rating')\nax[1,0].set_ylabel('crew normalized')\nax[1,0].set_title('crew')\n\nax[0,1].scatter(target_df['ratings'], feat_scaled['production_companies'], facecolor='red')\nax[0,1].set_xlabel('rating')\nax[0,1].set_ylabel('production companies normalized')\nax[0,1].set_title('Production Companies')\n\nax[1,1].scatter(target_df['ratings'], feat_scaled['keywords'], facecolor='orange')\nax[1,1].set_xlabel('rating')\nax[1,1].set_ylabel('keywords normalized')\nax[1,1].set_title('keywords')\n\nfig.suptitle(\"Corrlation between a movie's features and its rating\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b947a3c5-7d8c-4434-b40b-fd5d34162558",
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\ndef train_test_val_split(df_feat, df_target, train_frac):\n    train_features, test_features, train_target, test_target = train_test_split(df_feat, df_target, test_size = train_frac) #splitting training from rest of the dataset\n    return (train_features, train_target), (test_features, test_target)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f124d771-2584-4a0f-a8fd-666def1e4ff8",
      "cell_type": "code",
      "source": "(features_train, target_train), (features_test, target_test) = train_test_val_split(feat_scaled, target_df,0.7)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c4a67712-71c2-494f-bdec-15f2340a2cfa",
      "cell_type": "code",
      "source": "target_train.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0485e390-9d3d-4c83-a44e-6da696039af2",
      "cell_type": "code",
      "source": "from sklearn.linear_model import BayesianRidge",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "836caef1-ce9c-4728-ab06-b6588af7c631",
      "cell_type": "code",
      "source": "reg = BayesianRidge()\nreg.fit(features_train.values, target_train)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "77b8eb68-0ce5-419a-bb50-e1f875fe9896",
      "cell_type": "code",
      "source": "target_pred = reg.predict(features_test.values)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "34aed437-f09d-4578-9948-457b39f22ee0",
      "cell_type": "code",
      "source": "plt.axis([0,10,0,10])\nplt.scatter(target_test, target_pred)\n\nindex_arr = [n for n in range(11)]\nplt.plot(index_arr,'r--')             \nplt.xlabel(\"Movie Ratings\")\nplt.ylabel(\"Predicted Ratings\")\nplt.title(\"Movie ratings vs Predicted ratings\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "9cb66efe-ca9f-4fe2-800e-2c93129f6082",
      "cell_type": "code",
      "source": "from sklearn.metrics import r2_score\n\nscore = r2_score(target_test, target_pred)\n\nprint(\"R^2 Score for predictions:\", score)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}